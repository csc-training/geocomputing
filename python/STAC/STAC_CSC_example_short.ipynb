{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b465dd0-7f98-4c8f-9bdd-49eb93bbf98c",
   "metadata": {},
   "source": [
    "# Example how to use Paituli STAC with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a83e3c-68b5-45d9-91a3-0c9b3041cc21",
   "metadata": {},
   "source": [
    "This example shows how to use [Paituli STAC catalogue](https://paituli.csc.fi/geoserver/ogc/stac/v1) with Python.  \n",
    "\n",
    "This workflow is meant for processing big raster datasets, also with good support for time series. The main idea is to first define the search and processing as process graph. The downloading and processing is done lazily at the end, so that only needed data (good enough cloud-free image, only needed bands and area) is downloaded. The libraries take care of data download, so you do not need to know about file paths. These tools work best when data is provided as [Cloud-optimized GeoTiffs](https://www.cogeo.org/) (COGs).\n",
    "\n",
    "Dask is used for parallelization of computing, see [CSC Dask tutorial](https://docs.csc.fi/support/tutorials/dask-python/), inc how to use Dask with Jupyter in Puhti web interface and how to create batch jobs with Dask.\n",
    "\n",
    "The main steps:\n",
    "* Start Dask cluster\n",
    "* Query STAC catalogue to find images from area and time of interest and small cloud coverage, \n",
    "* Create first datacube, defining required bands and bbox.\n",
    "* Mosaic the images with median value, for each month.\n",
    "* Plot images\n",
    "* Calculate monthly NDVI-index\n",
    "* Save the NDVI-index to GeoTiff file.\n",
    "* Close Dask cluster\n",
    "\n",
    "At the end of the Notebook additionally is shown how to open files from STAC results with Rasterio.\n",
    "\n",
    "The example is based on:\n",
    "* [Stackstac documentation](https://stackstac.readthedocs.io/en/latest/basic.html),\n",
    "* Stacspec.org, Tutorials, [Access Sentinel 2 Data from AWS plotting](https://stacspec.org/en/tutorials/access-sentinel-2-data-aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8fead-d718-42f2-87f8-0769a27f3b63",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a78824-61f6-4b90-94a0-8c6de95e245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "import pystac_client\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95035902-f089-4ab9-afa1-b8446121d159",
   "metadata": {},
   "source": [
    "### Define STAC endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f855761-67a7-4352-8334-84784bf071a0",
   "metadata": {},
   "source": [
    "For using a specific STAC API, its endpoint must be defined.\n",
    "\n",
    "Open the catalog description from the small black triangle, after running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebfbac-3b89-4bfd-b947-016f1af35e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://paituli.csc.fi/geoserver/ogc/stac/v1\"\n",
    "catalog = pystac_client.Client.open(URL)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702fdf3-2602-47ea-b0fc-3b8794cba104",
   "metadata": {},
   "source": [
    "See basic info about the STAC catalog, Which collections are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b1da9-4a4b-408f-aadb-bbc1fc22b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_list = [(collection.title, collection.id) for collection in catalog.get_collections()]\n",
    "collections_list.sort()\n",
    "for collection in collections_list:\n",
    "    print(collection[0] + ': ' + collection[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432971d-b652-45a6-8dc6-f1e6a489eeed",
   "metadata": {},
   "source": [
    "Use **collection ID** for search here and later. In this example we use:\n",
    "\n",
    "* Sentinel-2 11-days data mosaics: **sentinel_2_11_days_mosaics_at_fmi** (original data as provided by ESA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1d6c9-b597-4696-bebe-d833aab27f79",
   "metadata": {},
   "source": [
    "## Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517825ab-a421-409a-91a4-071191f51886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lon, lat = 28.2, 63.62 #TiilikkajÃ¤rvi\n",
    "buffer = 1\n",
    "\n",
    "search = catalog.search(\n",
    "    bbox=[lon,lat,lon+buffer,lat+buffer],\n",
    "    collections=[\"sentinel_2_11_days_mosaics_at_fmi\"],\n",
    "    datetime=\"2021-08-01/2021-09-30\"\n",
    ")\n",
    "\n",
    "item_collection = search.item_collection()\n",
    "item_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d0d8c-316d-4cad-a4aa-8aaacc311b42",
   "metadata": {},
   "source": [
    "## Retrieving data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4a807-e6cc-4b67-b591-c352b07d5b8c",
   "metadata": {},
   "source": [
    "### Get data to Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a28943-73be-45f8-92d8-372d33eacc4c",
   "metadata": {},
   "source": [
    "We will use [Stackstac](https://stackstac.readthedocs.io/en) library for creating `Xarray DataArray` datacube from the STAC items. Alternatively, one could use [ODC STAC](https://odc-stac.readthedocs.io/en/latest/) or [Geowombad](https://geowombat.readthedocs.io/en/latest/index.html). There are some differences in details between the libraries, but in general they work in a similar way. See [ODC STAC discussion](https://github.com/opendatacube/odc-stac/issues/54), for differences between Stackstac and ODC STAC. \n",
    "\n",
    "Using the defaults, our data will be in its native coordinate reference system, at the finest resolution. But many also other values can be set here. \n",
    "\n",
    "* `bounds` - datacube bounds, use smaller bbox in data's UTM coordinate reference system, around the original search point and with width and height of `buffer`.\n",
    "* `epsg` - datacube coordinate system, given as EPSG code.\n",
    "* `chunksize` - how big part of data is analysed at once, see also [Dask chunksize](https://github.com/csc-training/geocomputing/blob/master/python/STAC/Readme.md#dask-chunksize). \n",
    "* `resolution` - pixel size\n",
    "* See [stackstac.stac()](https://stackstac.readthedocs.io/en/latest/api/main/stackstac.stack.html#stackstac.stack) documentation for more details. \n",
    "\n",
    "This will be fast, because the actual data is not fetched yet. How does the datacube look like? How many dimensions does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c78e1-945c-4679-924b-25aa78c20af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "x, y = pyproj.Proj(\"EPSG:3067\")(lon, lat)\n",
    "buffer = 2000 \n",
    "\n",
    "cube = stackstac.stack(\n",
    "    items=item_collection,\n",
    "    bounds=(x-buffer, y-buffer, x+buffer, y+buffer), \n",
    "    assets=[\"b04\", \"b03\", \"b02\", 'b08', \"quality_scene_classification\"],\n",
    "    chunksize=(-1,1,2048,2048),\n",
    "    resolution=10,\n",
    "    # resampling=Resampling.bilinear\n",
    "    epsg=3067\n",
    ").squeeze() \n",
    "# When item_collection contains multiple epsg's, epsg value needs to be provided\n",
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c7dbc-8ecb-46cc-9680-438732780e04",
   "metadata": {},
   "source": [
    "Remove pixels, which do not have data (clouds etc). For older mosaics this information is given in the asset `quality_scene_classification`. For later years, similar information is stored in asset `valid_observations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb1a8d-ec3c-4529-8aa5-83c7d2150790",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_stack = xr.where((cube.sel(band=\"quality_scene_classification\") >= 1), x = cube, y = np.nan)\n",
    "sentinel_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3818ef2-c0dd-4bbc-b65f-fe186bde6913",
   "metadata": {},
   "source": [
    "Use xarray's `resample` to create 1-month median composites. Note that we still only work on metadata/lazy-loaded data, hence we have not downloaded any data yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ab9c5-3c1c-4f0e-8a6e-285eb0337ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = sentinel_stack.resample(time=\"MS\").median(\"time\", keep_attrs=True)\n",
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1078f32-aff9-4d79-b3f9-931b28d3b3aa",
   "metadata": {},
   "source": [
    "So far no data has been downloaded, nor anything computed with actual data. In this example the final data size is very small, but Dask is good also in handling much bigger amounts of data, also bigger than fits to memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254400a-d279-44df-9087-f32626fb422a",
   "metadata": {},
   "source": [
    "It is also possible to [visualize, what Dask is going to do](https://docs.dask.org/en/stable/graphviz.html#). Sometimes some optimizations might be possible to make the graph better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e56c50-8cac-43f2-8517-a7b3df1b2354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.visualize(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5314a2a-9751-4b8a-9d18-621f0d6698ee",
   "metadata": {},
   "source": [
    "To start the data download and analysis process `compute()` could be used, but usually it is skipped and delayed even further until saving or plotting the data. The process can be followed from Dask Dashboard or Dask Lab Extension. Depending on the amount of data, this will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcfbf1-40ec-4c53-b319-09c9bf702417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data = monthly.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f986d75-4f9b-4119-b009-d426f95961f8",
   "metadata": {},
   "source": [
    "Show the resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1fa67f-c7d3-4e96-a17b-ec798496b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monthly.sel(band=[\"b04\", \"b03\", \"b02\"]).plot.imshow(row=\"time\", rgb=\"band\", robust=True, size=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d5580-7011-4022-80c8-43c36eb7202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monthly.sel(band=\"quality_scene_classification\").plot(row=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308eb84-9741-40c1-93fc-824536e93c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
